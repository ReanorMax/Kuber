apiVersion: v1
items:
- apiVersion: v1
  kind: Node
  metadata:
    annotations:
      node.alpha.kubernetes.io/ttl: "0"
      volumes.kubernetes.io/controller-managed-attach-detach: "true"
    creationTimestamp: "2025-10-08T09:37:34Z"
    labels:
      beta.kubernetes.io/arch: amd64
      beta.kubernetes.io/os: linux
      kubernetes.io/arch: amd64
      kubernetes.io/hostname: minikube
      kubernetes.io/os: linux
      minikube.k8s.io/commit: 65318f4cfff9c12cc87ec9eb8f4cdd57b25047f3
      minikube.k8s.io/name: minikube
      minikube.k8s.io/primary: "true"
      minikube.k8s.io/updated_at: 2025_10_08T12_37_37_0700
      minikube.k8s.io/version: v1.37.0
      node-role.kubernetes.io/control-plane: ""
      node.kubernetes.io/exclude-from-external-load-balancers: ""
    name: minikube
    resourceVersion: "367156"
    uid: 850f1836-825d-41f1-822a-692cc7c3da8f
  spec:
    podCIDR: 10.244.0.0/24
    podCIDRs:
    - 10.244.0.0/24
  status:
    addresses:
    - address: 192.168.49.2
      type: InternalIP
    - address: minikube
      type: Hostname
    allocatable:
      cpu: "2"
      ephemeral-storage: 50303512Ki
      hugepages-1Gi: "0"
      hugepages-2Mi: "0"
      memory: 4009164Ki
      pods: "110"
    capacity:
      cpu: "2"
      ephemeral-storage: 50303512Ki
      hugepages-1Gi: "0"
      hugepages-2Mi: "0"
      memory: 4009164Ki
      pods: "110"
    conditions:
    - lastHeartbeatTime: "2025-10-13T05:42:47Z"
      lastTransitionTime: "2025-10-08T09:37:32Z"
      message: kubelet has sufficient memory available
      reason: KubeletHasSufficientMemory
      status: "False"
      type: MemoryPressure
    - lastHeartbeatTime: "2025-10-13T05:42:47Z"
      lastTransitionTime: "2025-10-08T09:37:32Z"
      message: kubelet has no disk pressure
      reason: KubeletHasNoDiskPressure
      status: "False"
      type: DiskPressure
    - lastHeartbeatTime: "2025-10-13T05:42:47Z"
      lastTransitionTime: "2025-10-08T09:37:32Z"
      message: kubelet has sufficient PID available
      reason: KubeletHasSufficientPID
      status: "False"
      type: PIDPressure
    - lastHeartbeatTime: "2025-10-13T05:42:47Z"
      lastTransitionTime: "2025-10-08T09:37:34Z"
      message: kubelet is posting ready status
      reason: KubeletReady
      status: "True"
      type: Ready
    daemonEndpoints:
      kubeletEndpoint:
        Port: 10250
    images:
    - names:
      - grafana/grafana@sha256:a1701c2180249361737a99a01bc770db39381640e4d631825d38ff4535efa47d
      - grafana/grafana:12.1.1
      sizeBytes: 723282967
    - names:
      - registry.k8s.io/ingress-nginx/controller@sha256:1b044f6dcac3afbb59e05d98463f1dec6f3d3fb99940bc12ca5d80270358e3bd
      sizeBytes: 332491760
    - names:
      - quay.io/prometheus/prometheus@sha256:76947e7ef22f8a698fc638f706685909be425dbe09bd7a2cd7aca849f79b5f64
      - quay.io/prometheus/prometheus:v3.6.0
      sizeBytes: 313267336
    - names:
      - registry.k8s.io/ingress-nginx/controller@sha256:a886e56d532d1388c77c8340261149d974370edca1093af4c97a96fb1467cb39
      sizeBytes: 290034769
    - names:
      - registry.k8s.io/etcd@sha256:e36c081683425b5b3bc1425bc508b37e7107bb65dfa9367bf5a80125d431fa19
      - registry.k8s.io/etcd:3.6.4-0
      sizeBytes: 194905835
    - names:
      - nginx@sha256:a484819eb60211f5299034ac80f6a681b06f89e65866ce91f356ed7c72af059c
      - nginx:1.25
      sizeBytes: 187659947
    - names:
      - nginx@sha256:f79cde317d4d172a392978344034eed6dff5728a8e6d7a42f507504c23ecf8b8
      - nginx:latest
      sizeBytes: 159974475
    - names:
      - nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d
      - nginx:1.14.2
      sizeBytes: 109129446
    - names:
      - registry.k8s.io/kube-apiserver@sha256:fe86fe2f64021df8efa1a939a290bc21c8c128c66fc00ebbb6b5dea4c7a06812
      - registry.k8s.io/kube-apiserver:v1.34.0
      sizeBytes: 87968682
    - names:
      - quay.io/kiwigrid/k8s-sidecar@sha256:835d79d8fbae62e42d8a86929d4e3c5eec2e869255dd37756b5a3166c2f22309
      - quay.io/kiwigrid/k8s-sidecar:1.30.10
      sizeBytes: 79372365
    - names:
      - registry.k8s.io/coredns/coredns@sha256:e8c262566636e6bc340ece6473b0eed193cad045384401529721ddbe6463d31c
      - registry.k8s.io/coredns/coredns:v1.12.1
      sizeBytes: 75043396
    - names:
      - registry.k8s.io/kube-controller-manager@sha256:f8ba6c082136e2c85ce71628c59c6574ca4b67f162911cb200c0a51a5b9bff81
      - registry.k8s.io/kube-controller-manager:v1.34.0
      sizeBytes: 74923320
    - names:
      - quay.io/prometheus/alertmanager@sha256:27c475db5fb156cab31d5c18a4251ac7ed567746a2483ff264516437a39b15ba
      - quay.io/prometheus/alertmanager:v0.28.1
      sizeBytes: 72306219
    - names:
      - registry.k8s.io/kube-proxy@sha256:364da8a25c742d7a35e9635cb8cf42c1faf5b367760d0f9f9a75bdd1f9d52067
      - registry.k8s.io/kube-proxy:v1.34.0
      sizeBytes: 71871269
    - names:
      - quay.io/prometheus-operator/prometheus-operator@sha256:bbd4ff793b3677369005d2c167e5bba362ed31e4ad5f7a0085bdea2e84200c41
      - quay.io/prometheus-operator/prometheus-operator:v0.86.0
      sizeBytes: 65959457
    - names:
      - registry.k8s.io/kube-state-metrics/kube-state-metrics@sha256:2bbc915567334b13632bf62c0a97084aff72a36e13c4dabd5f2f11c898c5bacd
      - registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0
      sizeBytes: 62827286
    - names:
      - registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
      sizeBytes: 55313114
    - names:
      - registry.k8s.io/kube-scheduler@sha256:8fbe6d18415c8af9b31e177f6e444985f3a87349e083fe6eadd36753dddb17ff
      - registry.k8s.io/kube-scheduler:v1.34.0
      sizeBytes: 52763913
    - names:
      - quay.io/prometheus-operator/prometheus-config-reloader@sha256:a1ccf041f1abe8fecb7985964f5488019bdbeed6d3a88ede855cf69a8c374abb
      - quay.io/prometheus-operator/prometheus-config-reloader:v0.86.0
      sizeBytes: 45970977
    - names:
      - registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:3d671cf20a35cd94efc5dcd484970779eb21e7938c98fbc3673693b8a117cf39
      - registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.3
      sizeBytes: 42028952
    - names:
      - gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944
      - gcr.io/k8s-minikube/storage-provisioner:v5
      sizeBytes: 31465472
    - names:
      - quay.io/prometheus/node-exporter@sha256:d00a542e409ee618a4edc67da14dd48c5da66726bbd5537ab2af9c1dfc442c8a
      - quay.io/prometheus/node-exporter:v1.9.1
      sizeBytes: 24978622
    - names:
      - registry.k8s.io/pause@sha256:278fb9dbcca9518083ad1e11276933a2e96f23de604a3a08cc3c80002767d24c
      - registry.k8s.io/pause:3.10.1
      sizeBytes: 735760
    nodeInfo:
      architecture: amd64
      bootID: 08f58a43-5108-4b43-b628-dac4829c3b81
      containerRuntimeVersion: docker://28.4.0
      kernelVersion: 6.1.0-26-amd64
      kubeProxyVersion: ""
      kubeletVersion: v1.34.0
      machineID: ea5ef5188a294bb09ea240008cb6255a
      operatingSystem: linux
      osImage: Ubuntu 22.04.5 LTS
      swap:
        capacity: 1022357504
      systemUUID: cd201811-3db7-4710-a439-1cd8b0116c0d
    runtimeHandlers:
    - features:
        recursiveReadOnlyMounts: true
        userNamespaces: false
      name: ""
    - features:
        recursiveReadOnlyMounts: true
        userNamespaces: false
      name: io.containerd.runc.v2
    - features:
        recursiveReadOnlyMounts: true
        userNamespaces: false
      name: runc
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2025-10-08T09:37:35Z"
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "244"
    uid: 88360e1b-3df5-4db9-aaa2-2a321f345849
  spec:
    clusterIP: 10.96.0.1
    clusterIPs:
    - 10.96.0.1
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 8443
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2025-10-08T09:46:16Z"
    labels:
      app: nginx
    name: nginx
    namespace: default
    resourceVersion: "858"
    uid: 9ae7cad9-daeb-459b-bf4d-9bda4367d9ef
  spec:
    clusterIP: 10.100.245.250
    clusterIPs:
    - 10.100.245.250
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - nodePort: 31313
      port: 80
      protocol: TCP
      targetPort: 80
    selector:
      app: nginx
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx","app.kubernetes.io/part-of":"ingress-nginx","app.kubernetes.io/version":"1.11.0"},"name":"ingress-nginx-controller","namespace":"ingress-nginx"},"spec":{"ipFamilies":["IPv4"],"ipFamilyPolicy":"SingleStack","ports":[{"appProtocol":"http","name":"http","port":80,"protocol":"TCP","targetPort":"http"},{"appProtocol":"https","name":"https","port":443,"protocol":"TCP","targetPort":"https"}],"selector":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"type":"NodePort"}}
    creationTimestamp: "2025-10-10T12:53:11Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.0
    name: ingress-nginx-controller
    namespace: ingress-nginx
    resourceVersion: "149167"
    uid: 38e25561-3447-499e-8421-4ca378df12f6
  spec:
    clusterIP: 10.97.227.180
    clusterIPs:
    - 10.97.227.180
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: http
      name: http
      nodePort: 30258
      port: 80
      protocol: TCP
      targetPort: http
    - appProtocol: https
      name: https
      nodePort: 32605
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx","app.kubernetes.io/part-of":"ingress-nginx","app.kubernetes.io/version":"1.11.0"},"name":"ingress-nginx-controller-admission","namespace":"ingress-nginx"},"spec":{"ports":[{"appProtocol":"https","name":"https-webhook","port":443,"targetPort":"webhook"}],"selector":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"type":"ClusterIP"}}
    creationTimestamp: "2025-10-10T12:53:12Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.0
    name: ingress-nginx-controller-admission
    namespace: ingress-nginx
    resourceVersion: "149171"
    uid: f5f8e8d8-3d10-4b05-a5bb-3c2c10f0742f
  spec:
    clusterIP: 10.98.6.107
    clusterIPs:
    - 10.98.6.107
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: https
      name: https-webhook
      port: 443
      protocol: TCP
      targetPort: webhook
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/port: "9153"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-10-08T09:37:36Z"
    labels:
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: CoreDNS
    name: kube-dns
    namespace: kube-system
    resourceVersion: "290"
    uid: 9fbb4dd1-5826-44c9-b6e0-2c410ad3d2d1
  spec:
    clusterIP: 10.96.0.10
    clusterIPs:
    - 10.96.0.10
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: dns
      port: 53
      protocol: UDP
      targetPort: 53
    - name: dns-tcp
      port: 53
      protocol: TCP
      targetPort: 53
    - name: metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app: kube-prometheus-stack-coredns
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      jobLabel: coredns
      release: prometheus
    name: prometheus-kube-prometheus-coredns
    namespace: kube-system
    resourceVersion: "145332"
    uid: ab97ce2e-0c20-4cb0-a30f-e4b1026d742a
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app: kube-prometheus-stack-kube-controller-manager
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      jobLabel: kube-controller-manager
      release: prometheus
    name: prometheus-kube-prometheus-kube-controller-manager
    namespace: kube-system
    resourceVersion: "145331"
    uid: ff6c87e7-2e6c-4019-b729-7554a8fc8084
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 10257
      protocol: TCP
      targetPort: 10257
    selector:
      component: kube-controller-manager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app: kube-prometheus-stack-kube-etcd
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      jobLabel: kube-etcd
      release: prometheus
    name: prometheus-kube-prometheus-kube-etcd
    namespace: kube-system
    resourceVersion: "145328"
    uid: bb8183d1-d508-45f9-b32b-704f359c79cd
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 2381
      protocol: TCP
      targetPort: 2381
    selector:
      component: etcd
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app: kube-prometheus-stack-kube-proxy
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      jobLabel: kube-proxy
      release: prometheus
    name: prometheus-kube-prometheus-kube-proxy
    namespace: kube-system
    resourceVersion: "145329"
    uid: 605ed40c-2415-42ee-83eb-3bc1946518ee
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 10249
      protocol: TCP
      targetPort: 10249
    selector:
      k8s-app: kube-proxy
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app: kube-prometheus-stack-kube-scheduler
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      jobLabel: kube-scheduler
      release: prometheus
    name: prometheus-kube-prometheus-kube-scheduler
    namespace: kube-system
    resourceVersion: "145330"
    uid: 201570ed-a023-4959-aa44-090ae7164ad9
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 10259
      protocol: TCP
      targetPort: 10259
    selector:
      component: kube-scheduler
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2025-10-10T11:45:27Z"
    labels:
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: kubelet
      k8s-app: kubelet
    name: prometheus-kube-prometheus-kubelet
    namespace: kube-system
    resourceVersion: "145567"
    uid: 47e0f3ac-503d-4d7b-b430-3d4ca5d7aa83
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    - IPv6
    ipFamilyPolicy: RequireDualStack
    ports:
    - name: https-metrics
      port: 10250
      protocol: TCP
      targetPort: 10250
    - name: http-metrics
      port: 10255
      protocol: TCP
      targetPort: 10255
    - name: cadvisor
      port: 4194
      protocol: TCP
      targetPort: 4194
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2025-10-10T11:45:27Z"
    labels:
      app.kubernetes.io/managed-by: prometheus-operator
      managed-by: prometheus-operator
      operated-alertmanager: "true"
    name: alertmanager-operated
    namespace: monitoring
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      kind: Alertmanager
      name: prometheus-kube-prometheus-alertmanager
      uid: e031f689-32d5-45b6-85f5-6d6ae6fbbe8d
    resourceVersion: "145575"
    uid: 6ba5cbed-bac4-4ef7-ab0c-d1441ff73df6
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9093
      protocol: TCP
      targetPort: http-web
    - name: tcp-mesh
      port: 9094
      protocol: TCP
      targetPort: mesh-tcp
    - name: udp-mesh
      port: 9094
      protocol: UDP
      targetPort: mesh-udp
    publishNotReadyAddresses: true
    selector:
      app.kubernetes.io/name: alertmanager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 12.1.1
      helm.sh/chart: grafana-10.0.0
    name: prometheus-grafana
    namespace: monitoring
    resourceVersion: "145363"
    uid: b87f727f-9fa6-4f9a-a50d-57f02d87f943
  spec:
    clusterIP: 10.101.69.9
    clusterIPs:
    - 10.101.69.9
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      nodePort: 31282
      port: 80
      protocol: TCP
      targetPort: grafana
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: grafana
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app: kube-prometheus-stack-alertmanager
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      release: prometheus
      self-monitor: "true"
    name: prometheus-kube-prometheus-alertmanager
    namespace: monitoring
    resourceVersion: "145349"
    uid: 7a485b4b-e698-4c73-adea-0f37df8a759e
  spec:
    clusterIP: 10.102.82.194
    clusterIPs:
    - 10.102.82.194
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9093
      protocol: TCP
      targetPort: 9093
    - appProtocol: http
      name: reloader-web
      port: 8080
      protocol: TCP
      targetPort: reloader-web
    selector:
      alertmanager: prometheus-kube-prometheus-alertmanager
      app.kubernetes.io/name: alertmanager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/component: prometheus-operator
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      release: prometheus
    name: prometheus-kube-prometheus-operator
    namespace: monitoring
    resourceVersion: "145336"
    uid: f40331c1-bf80-4d60-8f42-fb2132eebe0b
  spec:
    clusterIP: 10.99.173.208
    clusterIPs:
    - 10.99.173.208
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      app: kube-prometheus-stack-operator
      release: prometheus
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app: kube-prometheus-stack-prometheus
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      release: prometheus
      self-monitor: "true"
    name: prometheus-kube-prometheus-prometheus
    namespace: monitoring
    resourceVersion: "145334"
    uid: 2e8dcfb5-6233-4687-9914-dddc359da62e
  spec:
    clusterIP: 10.109.71.185
    clusterIPs:
    - 10.109.71.185
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9090
      protocol: TCP
      targetPort: 9090
    - appProtocol: http
      name: reloader-web
      port: 8080
      protocol: TCP
      targetPort: reloader-web
    selector:
      app.kubernetes.io/name: prometheus
      operator.prometheus.io/name: prometheus-kube-prometheus-prometheus
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.17.0
      helm.sh/chart: kube-state-metrics-6.3.0
      release: prometheus
    name: prometheus-kube-state-metrics
    namespace: monitoring
    resourceVersion: "145337"
    uid: 989191a3-93e0-4f26-9658-26fcd9f26efd
  spec:
    clusterIP: 10.110.82.219
    clusterIPs:
    - 10.110.82.219
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: http
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: kube-state-metrics
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2025-10-10T11:45:27Z"
    labels:
      app.kubernetes.io/managed-by: prometheus-operator
      managed-by: prometheus-operator
      operated-prometheus: "true"
    name: prometheus-operated
    namespace: monitoring
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      kind: Prometheus
      name: prometheus-kube-prometheus-prometheus
      uid: fceeb994-7630-4f43-ac27-c12a5877c6a0
    resourceVersion: "145589"
    uid: 9a59e57e-3616-414a-85eb-035a49654b22
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9090
      protocol: TCP
      targetPort: http-web
    selector:
      app.kubernetes.io/name: prometheus
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-10-10T11:44:38Z"
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.9.1
      helm.sh/chart: prometheus-node-exporter-4.48.0
      jobLabel: node-exporter
      release: prometheus
    name: prometheus-prometheus-node-exporter
    namespace: monitoring
    resourceVersion: "145359"
    uid: 026f9ba8-4fbe-4083-87f0-c7ab917cd3d4
  spec:
    clusterIP: 10.104.155.59
    clusterIPs:
    - 10.104.155.59
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 9100
      protocol: TCP
      targetPort: 9100
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: prometheus-node-exporter
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"networking.k8s.io/v1","kind":"Ingress","metadata":{"annotations":{},"name":"grafana-ingress","namespace":"monitoring"},"spec":{"ingressClassName":"nginx","rules":[{"host":"grafana.local","http":{"paths":[{"backend":{"service":{"name":"prometheus-grafana","port":{"number":80}}},"path":"/","pathType":"Prefix"}]}}]}}
    creationTimestamp: "2025-10-10T12:56:26Z"
    generation: 1
    name: grafana-ingress
    namespace: monitoring
    resourceVersion: "149463"
    uid: fd8f8cd4-b9c9-4389-8dba-885e9b9d42f1
  spec:
    ingressClassName: nginx
    rules:
    - host: grafana.local
      http:
        paths:
        - backend:
            service:
              name: prometheus-grafana
              port:
                number: 80
          path: /
          pathType: Prefix
  status:
    loadBalancer:
      ingress:
      - ip: 192.168.49.2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"nginx"},"name":"nginx-deployment","namespace":"default"},"spec":{"replicas":3,"selector":{"matchLabels":{"app":"nginx"}},"template":{"metadata":{"labels":{"app":"nginx"}},"spec":{"containers":[{"image":"nginx:1.14.2","name":"nginx","ports":[{"containerPort":80}]}]}}}}
    creationTimestamp: "2025-10-09T08:25:17Z"
    generation: 4
    labels:
      app: nginx
      k8slens-edit-resource-version: v1
    name: nginx-deployment
    namespace: default
    resourceVersion: "139531"
    uid: 493ea2e0-3e59-4dba-88b6-045fddee433b
  spec:
    progressDeadlineSeconds: 600
    replicas: 3
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: nginx
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: nginx
      spec:
        containers:
        - image: nginx:1.25
          imagePullPolicy: IfNotPresent
          name: nginx
          ports:
          - containerPort: 80
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 3
    conditions:
    - lastTransitionTime: "2025-10-09T08:25:17Z"
      lastUpdateTime: "2025-10-10T09:42:02Z"
      message: ReplicaSet "nginx-deployment-77bf8679f9" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-10T09:46:12Z"
      lastUpdateTime: "2025-10-10T09:46:12Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 4
    readyReplicas: 3
    replicas: 3
    updatedReplicas: 3
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx","app.kubernetes.io/part-of":"ingress-nginx","app.kubernetes.io/version":"1.11.0"},"name":"ingress-nginx-controller","namespace":"ingress-nginx"},"spec":{"minReadySeconds":0,"revisionHistoryLimit":10,"selector":{"matchLabels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"}},"strategy":{"rollingUpdate":{"maxUnavailable":1},"type":"RollingUpdate"},"template":{"metadata":{"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx","app.kubernetes.io/part-of":"ingress-nginx","app.kubernetes.io/version":"1.11.0"}},"spec":{"containers":[{"args":["/nginx-ingress-controller","--election-id=ingress-nginx-leader","--controller-class=k8s.io/ingress-nginx","--ingress-class=nginx","--configmap=$(POD_NAMESPACE)/ingress-nginx-controller","--validating-webhook=:8443","--validating-webhook-certificate=/usr/local/certificates/cert","--validating-webhook-key=/usr/local/certificates/key","--enable-metrics=false"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"LD_PRELOAD","value":"/usr/local/lib/libmimalloc.so"}],"image":"registry.k8s.io/ingress-nginx/controller:v1.11.0@sha256:a886e56d532d1388c77c8340261149d974370edca1093af4c97a96fb1467cb39","imagePullPolicy":"IfNotPresent","lifecycle":{"preStop":{"exec":{"command":["/wait-shutdown"]}}},"livenessProbe":{"failureThreshold":5,"httpGet":{"path":"/healthz","port":10254,"scheme":"HTTP"},"initialDelaySeconds":10,"periodSeconds":10,"successThreshold":1,"timeoutSeconds":1},"name":"controller","ports":[{"containerPort":80,"name":"http","protocol":"TCP"},{"containerPort":443,"name":"https","protocol":"TCP"},{"containerPort":8443,"name":"webhook","protocol":"TCP"}],"readinessProbe":{"failureThreshold":3,"httpGet":{"path":"/healthz","port":10254,"scheme":"HTTP"},"initialDelaySeconds":10,"periodSeconds":10,"successThreshold":1,"timeoutSeconds":1},"resources":{"requests":{"cpu":"100m","memory":"90Mi"}},"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"add":["NET_BIND_SERVICE"],"drop":["ALL"]},"readOnlyRootFilesystem":false,"runAsNonRoot":true,"runAsUser":101,"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/usr/local/certificates/","name":"webhook-cert","readOnly":true}]}],"dnsPolicy":"ClusterFirst","nodeSelector":{"kubernetes.io/os":"linux"},"serviceAccountName":"ingress-nginx","terminationGracePeriodSeconds":300,"volumes":[{"name":"webhook-cert","secret":{"secretName":"ingress-nginx-admission"}}]}}}}
    creationTimestamp: "2025-10-10T12:53:12Z"
    generation: 1
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.0
    name: ingress-nginx-controller
    namespace: ingress-nginx
    resourceVersion: "149358"
    uid: ca5c33f9-8e09-426a-ba10-deb4e3b8abde
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
          app.kubernetes.io/version: 1.11.0
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --election-id=ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --ingress-class=nginx
          - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          - --enable-metrics=false
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.11.0@sha256:a886e56d532d1388c77c8340261149d974370edca1093af4c97a96fb1467cb39
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            name: https
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 101
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: ingress-nginx
        serviceAccountName: ingress-nginx
        terminationGracePeriodSeconds: 300
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: ingress-nginx-admission
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-10T12:53:12Z"
      lastUpdateTime: "2025-10-10T12:53:12Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-10T12:53:12Z"
      lastUpdateTime: "2025-10-10T12:55:24Z"
      message: ReplicaSet "ingress-nginx-controller-77bbd789bf" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-10-08T09:37:36Z"
    generation: 2
    labels:
      k8s-app: kube-dns
    name: coredns
    namespace: kube-system
    resourceVersion: "461"
    uid: faf01b34-25d7-4da8-821a-a328feadeb49
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        labels:
          k8s-app: kube-dns
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.12.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: liveness-probe
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          - containerPort: 8080
            name: liveness-probe
            protocol: TCP
          - containerPort: 8181
            name: readiness-probe
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: readiness-probe
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-08T09:37:41Z"
      lastUpdateTime: "2025-10-08T09:37:41Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-08T09:37:41Z"
      lastUpdateTime: "2025-10-08T09:38:21Z"
      message: ReplicaSet "coredns-66bc5c9577" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 12.1.1
      helm.sh/chart: grafana-10.0.0
    name: prometheus-grafana
    namespace: monitoring
    resourceVersion: "145724"
    uid: 51ec9e70-ba45-48c3-8ebe-efdb88a4d0a8
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: grafana
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
          checksum/secret: 255dcce8b67f5c37243e6ea276cff641014c46a38d3b0f5e8dfcd0452562869e
          kubectl.kubernetes.io/default-container: grafana
        labels:
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/name: grafana
          app.kubernetes.io/version: 12.1.1
          helm.sh/chart: grafana-10.0.0
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: NAMESPACE
            value: ALL
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: prometheus-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: prometheus-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.30.10
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: prometheus-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: prometheus-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.30.10
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: prometheus-grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: prometheus-grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:12.1.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          - containerPort: 6060
            name: profiling
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: prometheus-grafana
        serviceAccountName: prometheus-grafana
        shareProcessNamespace: false
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: prometheus-grafana
          name: config
        - emptyDir: {}
          name: storage
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: prometheus-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-10T11:46:42Z"
      lastUpdateTime: "2025-10-10T11:46:42Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-10T11:44:38Z"
      lastUpdateTime: "2025-10-10T11:46:42Z"
      message: ReplicaSet "prometheus-grafana-86d987c987" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    generation: 1
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/component: prometheus-operator
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      release: prometheus
    name: prometheus-kube-prometheus-operator
    namespace: monitoring
    resourceVersion: "145605"
    uid: f56e4a53-e500-4eb7-90bd-2768968715c5
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: kube-prometheus-stack-operator
        release: prometheus
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: kube-prometheus-stack-operator
          app.kubernetes.io/component: prometheus-operator
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
          app.kubernetes.io/part-of: kube-prometheus-stack
          app.kubernetes.io/version: 78.0.0
          chart: kube-prometheus-stack-78.0.0
          heritage: Helm
          release: prometheus
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --kubelet-service=kube-system/prometheus-kube-prometheus-kubelet
          - --kubelet-endpoints=true
          - --kubelet-endpointslice=false
          - --localhost=127.0.0.1
          - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.86.0
          - --config-reloader-cpu-request=0
          - --config-reloader-cpu-limit=0
          - --config-reloader-memory-request=0
          - --config-reloader-memory-limit=0
          - --thanos-default-base-image=quay.io/thanos/thanos:v0.39.2
          - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
          - --web.enable-tls=true
          - --web.cert-file=/cert/cert
          - --web.key-file=/cert/key
          - --web.listen-address=:10250
          - --web.tls-min-version=VersionTLS13
          env:
          - name: GOGC
            value: "30"
          image: quay.io/prometheus-operator/prometheus-operator:v0.86.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: kube-prometheus-stack
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cert
            name: tls-secret
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-prometheus-operator
        serviceAccountName: prometheus-kube-prometheus-operator
        terminationGracePeriodSeconds: 30
        volumes:
        - name: tls-secret
          secret:
            defaultMode: 420
            secretName: prometheus-kube-prometheus-admission
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-10T11:45:27Z"
      lastUpdateTime: "2025-10-10T11:45:27Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-10T11:44:38Z"
      lastUpdateTime: "2025-10-10T11:45:27Z"
      message: ReplicaSet "prometheus-kube-prometheus-operator-55567c669b" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.17.0
      helm.sh/chart: kube-state-metrics-6.3.0
      release: prometheus
    name: prometheus-kube-state-metrics
    namespace: monitoring
    resourceVersion: "145646"
    uid: a857ee16-fa4d-4983-b8f5-e8d237c1a325
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: kube-state-metrics
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-state-metrics
          app.kubernetes.io/part-of: kube-state-metrics
          app.kubernetes.io/version: 2.17.0
          helm.sh/chart: kube-state-metrics-6.3.0
          release: prometheus
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --port=8080
          - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
          image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 8081
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-state-metrics
        serviceAccountName: prometheus-kube-state-metrics
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-10T11:45:45Z"
      lastUpdateTime: "2025-10-10T11:45:45Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-10T11:44:38Z"
      lastUpdateTime: "2025-10-10T11:45:45Z"
      message: ReplicaSet "prometheus-kube-state-metrics-d687c76d7" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
      prometheus-operator-input-hash: "899276768969738879"
    creationTimestamp: "2025-10-10T11:45:27Z"
    generation: 1
    labels:
      alertmanager: prometheus-kube-prometheus-alertmanager
      app: kube-prometheus-stack-alertmanager
      app.kubernetes.io/instance: prometheus-kube-prometheus-alertmanager
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      managed-by: prometheus-operator
      release: prometheus
    name: alertmanager-prometheus-kube-prometheus-alertmanager
    namespace: monitoring
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      blockOwnerDeletion: true
      controller: true
      kind: Alertmanager
      name: prometheus-kube-prometheus-alertmanager
      uid: e031f689-32d5-45b6-85f5-6d6ae6fbbe8d
    resourceVersion: "145753"
    uid: 033f55be-02c2-47ad-b37b-8e0d00723521
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: Parallel
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        alertmanager: prometheus-kube-prometheus-alertmanager
        app.kubernetes.io/instance: prometheus-kube-prometheus-alertmanager
        app.kubernetes.io/managed-by: prometheus-operator
        app.kubernetes.io/name: alertmanager
    serviceName: alertmanager-operated
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/default-container: alertmanager
        labels:
          alertmanager: prometheus-kube-prometheus-alertmanager
          app.kubernetes.io/instance: prometheus-kube-prometheus-alertmanager
          app.kubernetes.io/managed-by: prometheus-operator
          app.kubernetes.io/name: alertmanager
          app.kubernetes.io/version: 0.28.1
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app.kubernetes.io/name
                    operator: In
                    values:
                    - alertmanager
                  - key: alertmanager
                    operator: In
                    values:
                    - prometheus-kube-prometheus-alertmanager
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - --config.file=/etc/alertmanager/config_out/alertmanager.env.yaml
          - --storage.path=/alertmanager
          - --data.retention=120h
          - --cluster.listen-address=
          - --web.listen-address=:9093
          - --web.external-url=http://prometheus-kube-prometheus-alertmanager.monitoring:9093
          - --web.route-prefix=/
          - --cluster.label=monitoring/prometheus-kube-prometheus-alertmanager
          - --cluster.peer=alertmanager-prometheus-kube-prometheus-alertmanager-0.alertmanager-operated:9094
          - --cluster.reconnect-timeout=5m
          - --web.config.file=/etc/alertmanager/web_config/web-config.yaml
          env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          image: quay.io/prometheus/alertmanager:v0.28.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /-/healthy
              port: http-web
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 3
          name: alertmanager
          ports:
          - containerPort: 9093
            name: http-web
            protocol: TCP
          - containerPort: 9094
            name: mesh-tcp
            protocol: TCP
          - containerPort: 9094
            name: mesh-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 10
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources:
            requests:
              memory: 200Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
          - mountPath: /etc/alertmanager/config_out
            name: config-out
            readOnly: true
          - mountPath: /etc/alertmanager/certs
            name: tls-assets
            readOnly: true
          - mountPath: /alertmanager
            name: alertmanager-prometheus-kube-prometheus-alertmanager-db
          - mountPath: /etc/alertmanager/web_config/web-config.yaml
            name: web-config
            readOnly: true
            subPath: web-config.yaml
          - mountPath: /etc/alertmanager/cluster_tls_config/cluster-tls-config.yaml
            name: cluster-tls-config
            readOnly: true
            subPath: cluster-tls-config.yaml
        - args:
          - --listen-address=:8080
          - --web-config-file=/etc/alertmanager/web_config/web-config.yaml
          - --reload-url=http://127.0.0.1:9093/-/reload
          - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
          - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
          - --watched-dir=/etc/alertmanager/config
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "-1"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.0
          imagePullPolicy: IfNotPresent
          name: config-reloader
          ports:
          - containerPort: 8080
            name: reloader-web
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
            readOnly: true
          - mountPath: /etc/alertmanager/config_out
            name: config-out
          - mountPath: /etc/alertmanager/web_config/web-config.yaml
            name: web-config
            readOnly: true
            subPath: web-config.yaml
        dnsPolicy: ClusterFirst
        initContainers:
        - args:
          - --watch-interval=0
          - --listen-address=:8081
          - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
          - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
          - --watched-dir=/etc/alertmanager/config
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "-1"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.0
          imagePullPolicy: IfNotPresent
          name: init-config-reloader
          ports:
          - containerPort: 8081
            name: reloader-init
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
            readOnly: true
          - mountPath: /etc/alertmanager/config_out
            name: config-out
          - mountPath: /etc/alertmanager/web_config/web-config.yaml
            name: web-config
            readOnly: true
            subPath: web-config.yaml
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 2000
          runAsGroup: 2000
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-prometheus-alertmanager
        serviceAccountName: prometheus-kube-prometheus-alertmanager
        terminationGracePeriodSeconds: 120
        volumes:
        - name: config-volume
          secret:
            defaultMode: 420
            secretName: alertmanager-prometheus-kube-prometheus-alertmanager-generated
        - name: tls-assets
          projected:
            defaultMode: 420
            sources:
            - secret:
                name: alertmanager-prometheus-kube-prometheus-alertmanager-tls-assets-0
        - emptyDir:
            medium: Memory
          name: config-out
        - name: web-config
          secret:
            defaultMode: 420
            secretName: alertmanager-prometheus-kube-prometheus-alertmanager-web-config
        - name: cluster-tls-config
          secret:
            defaultMode: 420
            secretName: alertmanager-prometheus-kube-prometheus-alertmanager-cluster-tls-config
        - emptyDir: {}
          name: alertmanager-prometheus-kube-prometheus-alertmanager-db
    updateStrategy:
      type: RollingUpdate
  status:
    availableReplicas: 1
    collisionCount: 0
    currentReplicas: 1
    currentRevision: alertmanager-prometheus-kube-prometheus-alertmanager-667fbc7dbb
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updateRevision: alertmanager-prometheus-kube-prometheus-alertmanager-667fbc7dbb
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
      prometheus-operator-input-hash: "6417999936957899321"
    creationTimestamp: "2025-10-10T11:45:27Z"
    generation: 1
    labels:
      app: kube-prometheus-stack-prometheus
      app.kubernetes.io/instance: prometheus-kube-prometheus-prometheus
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 78.0.0
      chart: kube-prometheus-stack-78.0.0
      heritage: Helm
      managed-by: prometheus-operator
      operator.prometheus.io/mode: server
      operator.prometheus.io/name: prometheus-kube-prometheus-prometheus
      operator.prometheus.io/shard: "0"
      prometheus: prometheus-kube-prometheus-prometheus
      release: prometheus
    name: prometheus-prometheus-kube-prometheus-prometheus
    namespace: monitoring
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      blockOwnerDeletion: true
      controller: true
      kind: Prometheus
      name: prometheus-kube-prometheus-prometheus
      uid: fceeb994-7630-4f43-ac27-c12a5877c6a0
    resourceVersion: "145816"
    uid: 6d58d69c-da40-4245-a28f-85764c785b65
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: Parallel
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus-kube-prometheus-prometheus
        app.kubernetes.io/managed-by: prometheus-operator
        app.kubernetes.io/name: prometheus
        operator.prometheus.io/name: prometheus-kube-prometheus-prometheus
        operator.prometheus.io/shard: "0"
        prometheus: prometheus-kube-prometheus-prometheus
    serviceName: prometheus-operated
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/default-container: prometheus
        labels:
          app.kubernetes.io/instance: prometheus-kube-prometheus-prometheus
          app.kubernetes.io/managed-by: prometheus-operator
          app.kubernetes.io/name: prometheus
          app.kubernetes.io/version: 3.6.0
          operator.prometheus.io/name: prometheus-kube-prometheus-prometheus
          operator.prometheus.io/shard: "0"
          prometheus: prometheus-kube-prometheus-prometheus
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app.kubernetes.io/name
                    operator: In
                    values:
                    - prometheus
                  - key: app.kubernetes.io/instance
                    operator: In
                    values:
                    - prometheus-kube-prometheus-prometheus
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
          - --web.enable-lifecycle
          - --web.external-url=http://prometheus-kube-prometheus-prometheus.monitoring:9090
          - --web.route-prefix=/
          - --storage.tsdb.retention.time=10d
          - --storage.tsdb.path=/prometheus
          - --storage.tsdb.wal-compression
          - --web.config.file=/etc/prometheus/web_config/web-config.yaml
          image: quay.io/prometheus/prometheus:v3.6.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 6
            httpGet:
              path: /-/healthy
              port: http-web
              scheme: HTTP
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          name: prometheus
          ports:
          - containerPort: 9090
            name: http-web
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            periodSeconds: 15
            successThreshold: 1
            timeoutSeconds: 3
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/prometheus/config_out
            name: config-out
            readOnly: true
          - mountPath: /etc/prometheus/certs
            name: tls-assets
            readOnly: true
          - mountPath: /prometheus
            name: prometheus-prometheus-kube-prometheus-prometheus-db
          - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
            name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
          - mountPath: /etc/prometheus/web_config/web-config.yaml
            name: web-config
            readOnly: true
            subPath: web-config.yaml
        - args:
          - --listen-address=:8080
          - --reload-url=http://127.0.0.1:9090/-/reload
          - --config-file=/etc/prometheus/config/prometheus.yaml.gz
          - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
          - --watched-dir=/etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "0"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.0
          imagePullPolicy: IfNotPresent
          name: config-reloader
          ports:
          - containerPort: 8080
            name: reloader-web
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/prometheus/config
            name: config
          - mountPath: /etc/prometheus/config_out
            name: config-out
          - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
            name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        dnsPolicy: ClusterFirst
        initContainers:
        - args:
          - --watch-interval=0
          - --listen-address=:8081
          - --config-file=/etc/prometheus/config/prometheus.yaml.gz
          - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
          - --watched-dir=/etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "0"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.0
          imagePullPolicy: IfNotPresent
          name: init-config-reloader
          ports:
          - containerPort: 8081
            name: reloader-init
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/prometheus/config
            name: config
          - mountPath: /etc/prometheus/config_out
            name: config-out
          - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
            name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 2000
          runAsGroup: 2000
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-prometheus-prometheus
        serviceAccountName: prometheus-kube-prometheus-prometheus
        shareProcessNamespace: false
        terminationGracePeriodSeconds: 600
        volumes:
        - name: config
          secret:
            defaultMode: 420
            secretName: prometheus-prometheus-kube-prometheus-prometheus
        - name: tls-assets
          projected:
            defaultMode: 420
            sources:
            - secret:
                name: prometheus-prometheus-kube-prometheus-prometheus-tls-assets-0
        - emptyDir:
            medium: Memory
          name: config-out
        - configMap:
            defaultMode: 420
            name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
          name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        - name: web-config
          secret:
            defaultMode: 420
            secretName: prometheus-prometheus-kube-prometheus-prometheus-web-config
        - emptyDir: {}
          name: prometheus-prometheus-kube-prometheus-prometheus-db
    updateStrategy:
      type: RollingUpdate
  status:
    availableReplicas: 1
    collisionCount: 0
    currentReplicas: 1
    currentRevision: prometheus-prometheus-kube-prometheus-prometheus-6dff644888
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updateRevision: prometheus-prometheus-kube-prometheus-prometheus-6dff644888
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2025-10-08T09:37:36Z"
    generation: 1
    labels:
      k8s-app: kube-proxy
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "410"
    uid: 50b84500-47a1-4e36-8166-de1661512c6a
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-proxy
    template:
      metadata:
        labels:
          k8s-app: kube-proxy
      spec:
        containers:
        - command:
          - /usr/local/bin/kube-proxy
          - --config=/var/lib/kube-proxy/config.conf
          - --hostname-override=$(NODE_NAME)
          env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          image: registry.k8s.io/kube-proxy:v1.34.0
          imagePullPolicy: IfNotPresent
          name: kube-proxy
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/kube-proxy
            name: kube-proxy
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-proxy
        serviceAccountName: kube-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-proxy
          name: kube-proxy
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-10-10T11:44:38Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.9.1
      helm.sh/chart: prometheus-node-exporter-4.48.0
      release: prometheus
    name: prometheus-prometheus-node-exporter
    namespace: monitoring
    resourceVersion: "145523"
    uid: 7a9350f8-9303-417b-b7de-32e8df42addc
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: prometheus-node-exporter
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: prometheus-node-exporter
          app.kubernetes.io/part-of: prometheus-node-exporter
          app.kubernetes.io/version: 1.9.1
          helm.sh/chart: prometheus-node-exporter-4.48.0
          jobLabel: node-exporter
          release: prometheus
      spec:
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: eks.amazonaws.com/compute-type
                  operator: NotIn
                  values:
                  - fargate
                - key: type
                  operator: NotIn
                  values:
                  - virtual-kubelet
        automountServiceAccountToken: false
        containers:
        - args:
          - --path.procfs=/host/proc
          - --path.sysfs=/host/sys
          - --path.rootfs=/host/root
          - --path.udev.data=/host/root/run/udev/data
          - --web.listen-address=[$(HOST_IP)]:9100
          - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
          - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs|erofs)$
          env:
          - name: HOST_IP
            value: 0.0.0.0
          image: quay.io/prometheus/node-exporter:v1.9.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http-metrics
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: node-exporter
          ports:
          - containerPort: 9100
            name: http-metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http-metrics
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /host/proc
            name: proc
            readOnly: true
          - mountPath: /host/sys
            name: sys
            readOnly: true
          - mountPath: /host/root
            mountPropagation: HostToContainer
            name: root
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: prometheus-prometheus-node-exporter
        serviceAccountName: prometheus-prometheus-node-exporter
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /proc
            type: ""
          name: proc
        - hostPath:
            path: /sys
            type: ""
          name: sys
        - hostPath:
            path: /
            type: ""
          name: root
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
kind: List
metadata:
  resourceVersion: ""
